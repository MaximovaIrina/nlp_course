{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram language models or how to write scientific papers (4 pts)\n",
    "\n",
    "We shall train our language model on a corpora of [ArXiv](http://arxiv.org/) articles and see if we can generate a new one!\n",
    "\n",
    "![img](https://media.npr.org/assets/img/2013/12/10/istock-18586699-monkey-computer_brick-16e5064d3378a14e0e4c2da08857efe03c04695e-s800-c85.jpg)\n",
    "\n",
    "_data by neelshah18 from [here](https://www.kaggle.com/neelshah18/arxivdataset/)_\n",
    "\n",
    "_Disclaimer: this has nothing to do with actual science. But it's fun, so who cares?!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.seterr(all=\"ignore\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-09 14:21:38--  https://www.dropbox.com/s/99az9n1b57qkd9j/arxivData.json.tar.gz?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.18, 2620:100:6026:18::a27d:4612\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/dl/99az9n1b57qkd9j/arxivData.json.tar.gz [following]\n",
      "--2022-10-09 14:21:38--  https://www.dropbox.com/s/dl/99az9n1b57qkd9j/arxivData.json.tar.gz\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc40b9ed356299c63314cdcb3119.dl.dropboxusercontent.com/cd/0/get/Budrc5gMsjn6nbayAZett8dihQm0Uqzye3iN0HiFY8LpX8UvQcWC73Rcs-c7HYMfvL4Ikq3e6nXrcdNmf4VCZ2ff5kQMj0m5d40YfJcBFvSewMJdQA8Oik5gE0OFKPcLZ9Q1AA9_azlynwQS9RL9GVSHReGIEorj6IHSzyQ2Y381mw/file?dl=1# [following]\n",
      "--2022-10-09 14:21:39--  https://uc40b9ed356299c63314cdcb3119.dl.dropboxusercontent.com/cd/0/get/Budrc5gMsjn6nbayAZett8dihQm0Uqzye3iN0HiFY8LpX8UvQcWC73Rcs-c7HYMfvL4Ikq3e6nXrcdNmf4VCZ2ff5kQMj0m5d40YfJcBFvSewMJdQA8Oik5gE0OFKPcLZ9Q1AA9_azlynwQS9RL9GVSHReGIEorj6IHSzyQ2Y381mw/file?dl=1\n",
      "Resolving uc40b9ed356299c63314cdcb3119.dl.dropboxusercontent.com (uc40b9ed356299c63314cdcb3119.dl.dropboxusercontent.com)... 162.125.70.15, 2620:100:6026:15::a27d:460f\n",
      "Connecting to uc40b9ed356299c63314cdcb3119.dl.dropboxusercontent.com (uc40b9ed356299c63314cdcb3119.dl.dropboxusercontent.com)|162.125.70.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18933283 (18M) [application/binary]\n",
      "Saving to: ‘arxivData.json.tar.gz’\n",
      "\n",
      "arxivData.json.tar. 100%[===================>]  18.06M  8.46MB/s    in 2.1s    \n",
      "\n",
      "2022-10-09 14:21:42 (8.46 MB/s) - ‘arxivData.json.tar.gz’ saved [18933283/18933283]\n",
      "\n",
      "arxivData.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>day</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>month</th>\n",
       "      <th>summary</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40619</th>\n",
       "      <td>[{'name': 'Tao Xiong'}, {'name': 'Yukun Bao'},...</td>\n",
       "      <td>15</td>\n",
       "      <td>1406.3792v1</td>\n",
       "      <td>[{'rel': 'related', 'href': 'http://dx.doi.org...</td>\n",
       "      <td>6</td>\n",
       "      <td>Highly accurate interval forecasting of electr...</td>\n",
       "      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Interval Forecasting of Electricity Demand: A ...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35596</th>\n",
       "      <td>[{'name': 'Jose L. Balcazar'}]</td>\n",
       "      <td>23</td>\n",
       "      <td>1002.4286v2</td>\n",
       "      <td>[{'rel': 'related', 'href': 'http://dx.doi.org...</td>\n",
       "      <td>2</td>\n",
       "      <td>Association rules are among the most widely em...</td>\n",
       "      <td>[{'term': 'cs.LO', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Redundancy, Deduction Schemes, and Minimum-Siz...</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35023</th>\n",
       "      <td>[{'name': 'Ella Gale'}]</td>\n",
       "      <td>19</td>\n",
       "      <td>1510.05705v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>10</td>\n",
       "      <td>Memristors have been suggested as a novel rout...</td>\n",
       "      <td>[{'term': 'cs.ET', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Single Memristor Logic Gates: From NOT to a Fu...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>[{'name': 'Nikhil Naik'}, {'name': 'Achuta Kad...</td>\n",
       "      <td>20</td>\n",
       "      <td>1501.04878v2</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>1</td>\n",
       "      <td>Continuous-wave Time-of-flight (TOF) range ima...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>A Light Transport Model for Mitigating Multipa...</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39907</th>\n",
       "      <td>[{'name': 'Thomas Shortell'}, {'name': 'Ali Sh...</td>\n",
       "      <td>19</td>\n",
       "      <td>1707.05905v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>7</td>\n",
       "      <td>Cloud computing is an important part of today'...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Secure SURF with Fully Homomorphic Encryption</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  author  day            id  \\\n",
       "40619  [{'name': 'Tao Xiong'}, {'name': 'Yukun Bao'},...   15   1406.3792v1   \n",
       "35596                     [{'name': 'Jose L. Balcazar'}]   23   1002.4286v2   \n",
       "35023                            [{'name': 'Ella Gale'}]   19  1510.05705v1   \n",
       "24975  [{'name': 'Nikhil Naik'}, {'name': 'Achuta Kad...   20  1501.04878v2   \n",
       "39907  [{'name': 'Thomas Shortell'}, {'name': 'Ali Sh...   19  1707.05905v1   \n",
       "\n",
       "                                                    link  month  \\\n",
       "40619  [{'rel': 'related', 'href': 'http://dx.doi.org...      6   \n",
       "35596  [{'rel': 'related', 'href': 'http://dx.doi.org...      2   \n",
       "35023  [{'rel': 'alternate', 'href': 'http://arxiv.or...     10   \n",
       "24975  [{'rel': 'alternate', 'href': 'http://arxiv.or...      1   \n",
       "39907  [{'rel': 'alternate', 'href': 'http://arxiv.or...      7   \n",
       "\n",
       "                                                 summary  \\\n",
       "40619  Highly accurate interval forecasting of electr...   \n",
       "35596  Association rules are among the most widely em...   \n",
       "35023  Memristors have been suggested as a novel rout...   \n",
       "24975  Continuous-wave Time-of-flight (TOF) range ima...   \n",
       "39907  Cloud computing is an important part of today'...   \n",
       "\n",
       "                                                     tag  \\\n",
       "40619  [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...   \n",
       "35596  [{'term': 'cs.LO', 'scheme': 'http://arxiv.org...   \n",
       "35023  [{'term': 'cs.ET', 'scheme': 'http://arxiv.org...   \n",
       "24975  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n",
       "39907  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n",
       "\n",
       "                                                   title  year  \n",
       "40619  Interval Forecasting of Electricity Demand: A ...  2014  \n",
       "35596  Redundancy, Deduction Schemes, and Minimum-Siz...  2010  \n",
       "35023  Single Memristor Logic Gates: From NOT to a Fu...  2015  \n",
       "24975  A Light Transport Model for Mitigating Multipa...  2015  \n",
       "39907      Secure SURF with Fully Homomorphic Encryption  2017  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative manual download link: https://yadi.sk/d/_nGyU2IajjR9-w\n",
    "!wget \"https://www.dropbox.com/s/99az9n1b57qkd9j/arxivData.json.tar.gz?dl=1\" -O arxivData.json.tar.gz\n",
    "!tar -xvzf arxivData.json.tar.gz\n",
    "data = pd.read_json(\"./arxivData.json\")\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Differential Contrastive Divergence ; This paper has been retracted.',\n",
       " 'What Does Artificial Life Tell Us About Death? ; Short philosophical essay',\n",
       " 'P=NP ; We claim to resolve the P=?NP problem via a formal argument for P=NP.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assemble lines: concatenate title and description\n",
    "lines = data.apply(lambda row: row['title'] + ' ; ' + row['summary'], axis=1).tolist()\n",
    "\n",
    "sorted(lines, key=len)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "You know the dril. The data is messy. Go clean the data. Use WordPunctTokenizer or something.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: convert lines (in-place) into strings of space-separated tokens. import & use WordPunctTokenizer\n",
    "\n",
    "# <YOUR CODE>\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "lines = [\" \".join(tokenizer.tokenize(l.lower())) for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sorted(lines, key=len)[0] == \\\n",
    "    'differential contrastive divergence ; this paper has been retracted .'\n",
    "assert sorted(lines, key=len)[2] == \\\n",
    "    'p = np ; we claim to resolve the p =? np problem via a formal argument for p = np .'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram Language Model (1point)\n",
    "\n",
    "A language model is a probabilistic model that estimates text probability: the joint probability of all tokens $w_t$ in text $X$: $P(X) = P(w_1, \\dots, w_T)$.\n",
    "\n",
    "It can do so by following the chain rule:\n",
    "$$P(w_1, \\dots, w_T) = P(w_1)P(w_2 \\mid w_1)\\dots P(w_T \\mid w_1, \\dots, w_{T-1}).$$ \n",
    "\n",
    "The problem with such approach is that the final term $P(w_T \\mid w_1, \\dots, w_{T-1})$ depends on $n-1$ previous words. This probability is impractical to estimate for long texts, e.g. $T = 1000$.\n",
    "\n",
    "One popular approximation is to assume that next word only depends on a finite amount of previous words:\n",
    "\n",
    "$$P(w_t \\mid w_1, \\dots, w_{t - 1}) = P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1})$$\n",
    "\n",
    "Such model is called __n-gram language model__ where n is a parameter. For example, in 3-gram language model, each word only depends on 2 previous words. \n",
    "\n",
    "$$\n",
    "    P(w_1, \\dots, w_n) = \\prod_t P(w_t \\mid w_{t - n + 1}, \\dots, w_{t - 1}).\n",
    "$$\n",
    "\n",
    "You can also sometimes see such approximation under the name of _n-th order markov assumption_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first stage to building such a model is counting all word occurences given N-1 previous words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# special tokens: \n",
    "# - unk represents absent tokens, \n",
    "# - eos is a special token after the end of sequence\n",
    "\n",
    "UNK, EOS = \"_UNK_\", \"_EOS_\"\n",
    "\n",
    "def count_ngrams(lines, n):\n",
    "    \"\"\"\n",
    "    Count how many times each word occured after (n - 1) previous words\n",
    "    :param lines: an iterable of strings with space-separated tokens\n",
    "    :returns: a dictionary { tuple(prefix_tokens): {next_token_1: count_1, next_token_2: count_2}}\n",
    "\n",
    "    When building counts, please consider the following two edge cases\n",
    "    - if prefix is shorter than (n - 1) tokens, it should be padded with UNK. For n=3,\n",
    "      empty prefix: \"\" -> (UNK, UNK)\n",
    "      short prefix: \"the\" -> (UNK, the)\n",
    "      long prefix: \"the new approach\" -> (new, approach)\n",
    "    - you should add a special token, EOS, at the end of each sequence\n",
    "      \"... with deep neural networks .\" -> (..., with, deep, neural, networks, ., EOS)\n",
    "      count the probability of this token just like all others.\n",
    "    \"\"\"\n",
    "    counts = defaultdict(Counter)\n",
    "    # counts[(word1, word2)][word3] = how many times word3 occured after (word1, word2)\n",
    "\n",
    "    # <YOUR CODE>\n",
    "    for line in lines:\n",
    "        tokens = [UNK] * (n - 1) + line.split() + [EOS]\n",
    "        for i in range((n - 1), len(tokens)):\n",
    "            ngram = tokens[i - (n - 1): i + 1]\n",
    "            counts[tuple(ngram[:-1])][ngram[-1]] += 1\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test it\n",
    "dummy_lines = sorted(lines, key=len)[:100]\n",
    "dummy_counts = count_ngrams(dummy_lines, n=3)\n",
    "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
    "assert len(dummy_counts[('_UNK_', '_UNK_')]) == 78\n",
    "assert dummy_counts['_UNK_', 'a']['note'] == 3\n",
    "assert dummy_counts['p', '=']['np'] == 2\n",
    "assert dummy_counts['author', '.']['_EOS_'] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we can count N-grams, we can build a probabilistic language model.\n",
    "The simplest way to compute probabilities is in proporiton to counts:\n",
    "\n",
    "$$ P(w_t | prefix) = { Count(prefix, w_t) \\over \\sum_{\\hat w} Count(prefix, \\hat w) } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModel:    \n",
    "    def __init__(self, lines, n):\n",
    "        \"\"\" \n",
    "        Train a simple count-based language model: \n",
    "        compute probabilities P(w_t | prefix) given ngram counts\n",
    "        \n",
    "        :param n: computes probability of next token given (n - 1) previous words\n",
    "        :param lines: an iterable of strings with space-separated tokens\n",
    "        \"\"\"\n",
    "        assert n >= 1\n",
    "        self.n = n\n",
    "    \n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        \n",
    "        # compute token proabilities given counts\n",
    "        self.probs = defaultdict(Counter)\n",
    "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
    "        \n",
    "        # populate self.probs with actual probabilities\n",
    "        # <YOUR CODE>\n",
    "        for prefix in counts:\n",
    "            prefix_sum = sum(counts[prefix].values())\n",
    "            for word in counts[prefix]:\n",
    "                self.probs[prefix][word] = counts[prefix][word] / prefix_sum\n",
    "            \n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :returns: a dictionary {token : it's probability} for all tokens with positive probabilities\n",
    "        \"\"\"\n",
    "        prefix = prefix.split()\n",
    "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
    "        prefix = [ UNK ] * (self.n - 1 - len(prefix)) + prefix\n",
    "        return self.probs[tuple(prefix)]\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :param next_token: the next token to predict probability for\n",
    "        :returns: P(next_token|prefix) a single number, 0 <= P <= 1\n",
    "        \"\"\"\n",
    "        return self.get_possible_next_tokens(prefix).get(next_token, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
    "\n",
    "p_initial = dummy_lm.get_possible_next_tokens('') # '' -> ['_UNK_', '_UNK_']\n",
    "assert np.allclose(p_initial['learning'], 0.02)\n",
    "assert np.allclose(p_initial['a'], 0.13)\n",
    "assert np.allclose(p_initial.get('meow', 0), 0)\n",
    "assert np.allclose(sum(p_initial.values()), 1)\n",
    "\n",
    "p_a = dummy_lm.get_possible_next_tokens('a') # '' -> ['_UNK_', 'a']\n",
    "assert np.allclose(p_a['machine'], 0.15384615)\n",
    "assert np.allclose(p_a['note'], 0.23076923)\n",
    "assert np.allclose(p_a.get('the', 0), 0)\n",
    "assert np.allclose(sum(p_a.values()), 1)\n",
    "\n",
    "assert np.allclose(dummy_lm.get_possible_next_tokens('a note')['on'], 1)\n",
    "assert dummy_lm.get_possible_next_tokens('a machine') == \\\n",
    "    dummy_lm.get_possible_next_tokens(\"there have always been ghosts in a machine\"), \\\n",
    "    \"your 3-gram model should only depend on 2 previous words\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've got a working n-gram language model, let's see what sequences it can generate. But first, let's train it on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = NGramLanguageModel(lines, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of generating sequences is... well, it's sequential. You maintain a list of tokens and iteratively add next token by sampling with probabilities.\n",
    "\n",
    "$ X = [] $\n",
    "\n",
    "__forever:__\n",
    "* $w_{next} \\sim P(w_{next} | X)$\n",
    "* $X = concat(X, w_{next})$\n",
    "\n",
    "\n",
    "Instead of sampling with probabilities, one can also try always taking most likely token, sampling among top-K most likely tokens or sampling with temperature. In the latter case (temperature), one samples from\n",
    "\n",
    "$$w_{next} \\sim {P(w_{next} | X) ^ {1 / \\tau} \\over \\sum_{\\hat w} P(\\hat w | X) ^ {1 / \\tau}}$$\n",
    "\n",
    "Where $\\tau > 0$ is model temperature. If $\\tau << 1$, more likely tokens will be sampled with even higher probability while less likely tokens will vanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_token(lm, prefix, temperature=1.0):\n",
    "    \"\"\"\n",
    "    return next token after prefix;\n",
    "    :param temperature: samples proportionally to lm probabilities ^ (1 / temperature)\n",
    "        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
    "    \"\"\"\n",
    "    # <YOUR CODE>\n",
    "    tokens, probs = zip(*lm.get_possible_next_tokens(prefix).items())\n",
    "    if temperature == 0:\n",
    "        return tokens[np.argmax(probs)]\n",
    "    probs = np.array(probs) ** (1 / temperature)\n",
    "    probs /= sum(probs)\n",
    "    return np.random.choice(tokens, p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks nice!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "test_freqs = Counter([get_next_token(lm, 'there have') for _ in range(10000)])\n",
    "assert 250 < test_freqs['not'] < 450\n",
    "assert 8500 < test_freqs['been'] < 9500\n",
    "assert 1 < test_freqs['lately'] < 200\n",
    "\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=1.0) for _ in range(10000)])\n",
    "assert 1500 < test_freqs['learning'] < 3000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.5) for _ in range(10000)])\n",
    "assert 8000 < test_freqs['learning'] < 9000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.0) for _ in range(10000)])\n",
    "assert test_freqs['learning'] == 10000\n",
    "\n",
    "print(\"Looks nice!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have fun with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial life tell us what kind of pgt which is so central to these classes . in addition to contributing to this phenomenon . _EOS_\n"
     ]
    }
   ],
   "source": [
    "prefix = 'artificial' # <- your ideas :)\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bridging the gap between the two - stage training strategy is employed for clutter estimation while generalized labeled multi - scale applications . in the context of a general framework for the task as a result , the proposed algorithm , and the other hand , we demonstrate the effectiveness of our approach is able to achieve the same time , we propose a novel method for the case of the proposed method . we show that the proposed model is based on the problem of learning . we propose a framework for multi - task learning to play a central problem\n"
     ]
    }
   ],
   "source": [
    "prefix = 'bridging the' # <- more of your ideas\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix, temperature=0.5)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "        \n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__More in the homework:__ nucleous sampling, top-k sampling, beam search(not for the faint of heart)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating language models: perplexity (1point)\n",
    "\n",
    "Perplexity is a measure of how well does your model approximate true probability distribution behind data. __Smaller perplexity = better model__.\n",
    "\n",
    "To compute perplexity on one sentence, use:\n",
    "$$\n",
    "    {\\mathbb{P}}(w_1 \\dots w_N) = P(w_1, \\dots, w_N)^{-\\frac1N} = \\left( \\prod_t P(w_t \\mid w_{t - n}, \\dots, w_{t - 1})\\right)^{-\\frac1N},\n",
    "$$\n",
    "\n",
    "\n",
    "On the corpora level, perplexity is a product of probabilities of all tokens in all sentences to the power of 1, divided by __total length of all sentences__ in corpora.\n",
    "\n",
    "This number can quickly get too small for float32/float64 precision, so we recommend you to first compute log-perplexity (from log-probabilities) and then take the exponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(lm, lines, min_logprob=np.log(10 ** -50.)):\n",
    "    \"\"\"\n",
    "    :param lines: a list of strings with space-separated tokens\n",
    "    :param min_logprob: if log(P(w | ...)) is smaller than min_logprop, set it equal to min_logrob\n",
    "    :returns: corpora-level perplexity - a single scalar number from the formula above\n",
    "    \n",
    "    Note: do not forget to compute P(w_first | empty) and P(eos | full_sequence)\n",
    "    \n",
    "    PLEASE USE lm.get_next_token_prob and NOT lm.get_possible_next_tokens\n",
    "    \"\"\"\n",
    "    # <YOUR CODE>\n",
    "    N = 0\n",
    "    log_perplexity = 0\n",
    "\n",
    "    for line in lines:\n",
    "        tokens = [UNK] * (lm.n - 1) + line.split() + [EOS]\n",
    "        for i in range((lm.n - 1), len(tokens)):\n",
    "            ngram = tokens[i - (lm.n - 1): i + 1]\n",
    "            prob = lm.get_next_token_prob(\" \".join(ngram[:-1]), ngram[-1])\n",
    "            log_perplexity += max(min_logprob, np.log(prob)) \n",
    "            N += 1\n",
    "\n",
    "    return np.exp(-(1 / N) * log_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexities: ppx1=318.213 ppx3=1.520 ppx10=1.184\n"
     ]
    }
   ],
   "source": [
    "lm1 = NGramLanguageModel(dummy_lines, n=1)\n",
    "lm3 = NGramLanguageModel(dummy_lines, n=3)\n",
    "lm10 = NGramLanguageModel(dummy_lines, n=10)\n",
    "\n",
    "ppx1 = perplexity(lm1, dummy_lines)\n",
    "ppx3 = perplexity(lm3, dummy_lines)\n",
    "ppx10 = perplexity(lm10, dummy_lines)\n",
    "ppx_missing = perplexity(lm3, ['the jabberwock , with eyes of flame , '])  # thanks, L. Carrol\n",
    "\n",
    "print(\"Perplexities: ppx1=%.3f ppx3=%.3f ppx10=%.3f\" % (ppx1, ppx3, ppx10))\n",
    "\n",
    "assert all(0 < ppx < 500 for ppx in (ppx1, ppx3, ppx10)), \"perplexity should be nonnegative and reasonably small\"\n",
    "assert ppx1 > ppx3 > ppx10, \"higher N models should overfit and \"\n",
    "assert np.isfinite(ppx_missing) and ppx_missing > 10 ** 6, \"missing words should have large but finite perplexity. \" \\\n",
    "    \" Make sure you use min_logprob right\"\n",
    "assert np.allclose([ppx1, ppx3, ppx10], (318.2132342216302, 1.5199996213739575, 1.1838145037901249))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's measure the actual perplexity: we'll split the data into train and test and score model on test data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 1832.23136\n",
      "N = 2, Perplexity = 85653987.28774\n",
      "N = 3, Perplexity = 61999196259042902147072.00000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_lines, test_lines = train_test_split(lines, test_size=0.25, random_state=42)\n",
    "\n",
    "for n in (1, 2, 3):\n",
    "    lm = NGramLanguageModel(n=n, lines=train_lines)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whoops, it just blew up :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LM Smoothing\n",
    "\n",
    "The problem with our simple language model is that whenever it encounters an n-gram it has never seen before, it assigns it with the probabilitiy of 0. Every time this happens, perplexity explodes.\n",
    "\n",
    "To battle this issue, there's a technique called __smoothing__. The core idea is to modify counts in a way that prevents probabilities from getting too low. The simplest algorithm here is Additive smoothing (aka [Lapace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)):\n",
    "\n",
    "$$ P(w_t | prefix) = { Count(prefix, w_t) + \\delta \\over \\sum_{\\hat w} (Count(prefix, \\hat w) + \\delta) } $$\n",
    "\n",
    "If counts for a given prefix are low, additive smoothing will adjust probabilities to a more uniform distribution. Not that the summation in the denominator goes over _all words in the vocabulary_.\n",
    "\n",
    "Here's an example code we've implemented for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceLanguageModel(NGramLanguageModel): \n",
    "    \"\"\" this code is an example, no need to change anything \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        self.n = n\n",
    "        counts = count_ngrams(lines, self.n)\n",
    "        self.vocab = set(token for token_counts in counts.values() for token in token_counts)\n",
    "        self.probs = defaultdict(Counter)\n",
    "\n",
    "        for prefix in counts:\n",
    "            token_counts = counts[prefix]\n",
    "            total_count = sum(token_counts.values()) + delta * len(self.vocab)\n",
    "            self.probs[prefix] = {token: (token_counts[token] + delta) / total_count\n",
    "                                          for token in token_counts}\n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "        missing_prob = missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        return {token: token_probs.get(token, missing_prob) for token in self.vocab}\n",
    "    \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        if next_token in token_probs:\n",
    "            return token_probs[next_token]\n",
    "        else:\n",
    "            missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "            missing_prob_total = max(0, missing_prob_total) # prevent rounding errors\n",
    "            return missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test that it's a valid probability model\n",
    "for n in (1, 2, 3):\n",
    "    dummy_lm = LaplaceLanguageModel(dummy_lines, n=n)\n",
    "    assert np.allclose(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 977.67559\n",
      "N = 2, Perplexity = 470.48021\n",
      "N = 3, Perplexity = 3679.44765\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = LaplaceLanguageModel(train_lines, n=n, delta=0.1)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: try to sample tokens from such a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kneser-Ney smoothing (2 points)\n",
    "\n",
    "Additive smoothing is simple, reasonably good but definitely not a State of The Art algorithm.\n",
    "\n",
    "\n",
    "Your final task in this notebook is to implement [Kneser-Ney](https://en.wikipedia.org/wiki/Kneser%E2%80%93Ney_smoothing) smoothing.\n",
    "\n",
    "It can be computed recurrently, for n>1:\n",
    "\n",
    "$$P_{kn}(w_t | prefix_{n-1}) = { \\max(0, Count(prefix_{n-1}, w_t) - \\delta) \\over \\sum_{\\hat w} Count(prefix_{n-1}, \\hat w)} + \\lambda_{prefix_{n-1}} \\cdot P_{kn}(w_t | prefix_{n-2})$$\n",
    "\n",
    "where\n",
    "- $prefix_{n-1}$ is a tuple of {n-1} previous tokens\n",
    "- $lambda_{prefix_{n-1}}$ is a normalization constant chosen so that probabilities add up to 1\n",
    "- Unigram $P_{kn}(w_t | prefix_{n-2})$ corresponds to Kneser Ney smoothing for {N-1}-gram language model.\n",
    "- Unigram $P_{kn}(w_t)$ is a special case: how likely it is to see x_t in an unfamiliar context\n",
    "\n",
    "See lecture slides or wiki for more detailed formulae.\n",
    "\n",
    "__Your task__ is to\n",
    "- implement KneserNeyLanguageModel\n",
    "- test it on 1-3 gram language models\n",
    "- find optimal (within reason) smoothing delta for 3-gram language model with Kneser-Ney smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KneserNeyLanguageModel(NGramLanguageModel): \n",
    "    \"\"\" A template for Kneser-Ney language model. Default delta may be suboptimal. \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        self.n = n\n",
    "        # <YOUR CODE>\n",
    "        assert n >= 1\n",
    "        self.delta = delta\n",
    "        self.counts = count_ngrams(lines, n)\n",
    "        self.vocab = set(token for token_counts in self.counts.values() for token in token_counts)\n",
    "        self.probs = defaultdict(Counter)\n",
    "        if n == 1:\n",
    "            for prefix in self.counts:\n",
    "                prefix_counts = self.counts[prefix]\n",
    "                prefix_sum = sum(prefix_counts.values())\n",
    "                for word in self.counts[prefix]:\n",
    "                    self.probs[prefix][word] = prefix_counts[word] / prefix_sum\n",
    "        else:\n",
    "            self.Sub_Model = KneserNeyLanguageModel(lines, n - 1, delta)\n",
    "            for prefix in self.counts:\n",
    "                prefix_counts = self.counts[prefix]\n",
    "                prefix_sum = sum(prefix_counts.values())\n",
    "                lamda = (delta * len(prefix_counts)) / prefix_sum \n",
    "                for word in self.counts[prefix]:\n",
    "                    cur_prob = max(0, prefix_counts[word] - delta) / prefix_sum\n",
    "                    reduced_prefix = ' '.join(prefix[1:])\n",
    "                    prev_prob = self.Sub_Model.get_next_token_prob(reduced_prefix, word)\n",
    "                    self.probs[prefix][word] = cur_prob + lamda * prev_prob\n",
    "    \n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        # <YOUR CODE>\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        missing_prob_total = 1.0 - sum(token_probs.values())\n",
    "        missing_prob = missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n",
    "        return {token: token_probs.get(token, missing_prob) for token in self.vocab}\n",
    "    \n",
    "    def prefix_preproc(self, prefix):\n",
    "        prefix = prefix.split()\n",
    "        prefix = [UNK] * (self.n - 1 - len(prefix)) + prefix\n",
    "        prefix = tuple(prefix)\n",
    "        return prefix\n",
    "        \n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        # <YOUR CODE>\n",
    "        token_probs = super().get_possible_next_tokens(prefix)\n",
    "        if next_token in token_probs:\n",
    "            return token_probs[next_token]\n",
    "        else:\n",
    "            if self.n == 1:\n",
    "                return 0\n",
    "            \n",
    "            prefix = self.prefix_preproc(prefix)\n",
    "            prefix_counts = self.counts[prefix]\n",
    "            prefix_sum = sum(prefix_counts.values())\n",
    "            \n",
    "            lamda = (self.delta * len(prefix_counts)) / prefix_sum if prefix_sum else 1\n",
    "            reduced_prefix = ' '.join(prefix[1:])\n",
    "            prev_prob = self.Sub_Model.get_next_token_prob(reduced_prefix, next_token)\n",
    "            return lamda * prev_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test that it's a valid probability model\n",
    "for n in (1, 2, 3):\n",
    "    dummy_lm = KneserNeyLanguageModel(dummy_lines, n=n)\n",
    "    assert np.allclose(sum([dummy_lm.get_next_token_prob('a', w_i) for w_i in dummy_lm.vocab]), 1), \"I told you not to break anything! :)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1, Perplexity = 1832.23136\n",
      "N = 2, Perplexity = 426.28450\n",
      "N = 3, Perplexity = 330.21258\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3):\n",
    "    lm = KneserNeyLanguageModel(train_lines, n=n)\n",
    "    ppx = perplexity(lm, test_lines)\n",
    "    print(\"N = %i, Perplexity = %.5f\" % (n, ppx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:21<00:00, 40.30s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n = 3\n",
    "deltas = (0.01, 0.25, 0.5, 0.75, 1)\n",
    "deltas_ppx = {}\n",
    "\n",
    "for delta in tqdm(deltas):\n",
    "    lm = KneserNeyLanguageModel(train_lines, n=n, delta=delta)\n",
    "    deltas_ppx[delta] = perplexity(lm, test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Evaluation of KneserNeyLanguageModel(n=3)')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(deltas_ppx.keys(), deltas_ppx.values())\n",
    "plt.ylabel(\"perplexity\")\n",
    "plt.xlabel(\"delta\")\n",
    "plt.title(\"Evaluation of KneserNeyLanguageModel(n=3)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
